---
http_interactions:
- request:
    method: post
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=<GEMINI_API_KEY>
    body:
      encoding: UTF-8
      string: '{"model":"gemini-2.0-flash","contents":[{"parts":[{"text":"What''s
        the weather in New York?"}]}],"generationConfig":{"temperature":0.1},"systemInstruction":{"parts":[{"text":"You
        are a helpful assistant. When you encounter a question that you can answer
        by calling a function, you must always use the provided function. Always respond
        using the function call format, not with your own text. You are a helpful
        assistant that ALWAYS uses the provided functions. ALWAYS call the get_weather
        function when asked about weather. NEVER respond with your own text when a
        function is available. ALWAYS use a function for the query. It is EXTREMELY
        IMPORTANT that you ONLY respond with a function call and NO regular text."}]},"tools":[{"functionDeclarations":{"name":"get_weather","description":"Get
        the current weather for a location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
        city and state, e.g. New York, NY"}},"required":["location"]}}}],"toolConfig":{"function_calling_config":{"mode":"AUTO"}}}'
    headers:
      User-Agent:
      - Faraday v2.13.0
      Accept:
      - application/json
      Content-Type:
      - application/json
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
  response:
    status:
      code: 200
      message: OK
    headers:
      Content-Type:
      - application/json; charset=UTF-8
      Vary:
      - Origin
      - Referer
      - X-Origin
      Date:
      - Sat, 17 May 2025 17:20:44 GMT
      Server:
      - scaffolding on HTTPServer2
      X-Xss-Protection:
      - '0'
      X-Frame-Options:
      - SAMEORIGIN
      X-Content-Type-Options:
      - nosniff
      Server-Timing:
      - gfet4t7; dur=373
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Transfer-Encoding:
      - chunked
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "functionCall": {
                      "name": "get_weather",
                      "args": {
                        "location": "New York, NY"
                      }
                    }
                  }
                ],
                "role": "model"
              },
              "finishReason": "STOP",
              "avgLogprobs": -0.0096233868971467018
            }
          ],
          "usageMetadata": {
            "promptTokenCount": 141,
            "candidatesTokenCount": 8,
            "totalTokenCount": 149,
            "promptTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 141
              }
            ],
            "candidatesTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 8
              }
            ]
          },
          "modelVersion": "gemini-2.0-flash"
        }
  recorded_at: Sat, 17 May 2025 17:20:44 GMT
- request:
    method: post
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=<GEMINI_API_KEY>
    body:
      encoding: UTF-8
      string: '{"model":"gemini-2.0-flash","contents":[{"parts":[{"text":"Function
        get_weather returned: {:temperature=>72, :conditions=>\"sunny\", :humidity=>45}"}]}]}'
    headers:
      User-Agent:
      - Faraday v2.13.0
      Accept:
      - application/json
      Content-Type:
      - application/json
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
  response:
    status:
      code: 200
      message: OK
    headers:
      Content-Type:
      - application/json; charset=UTF-8
      Vary:
      - Origin
      - Referer
      - X-Origin
      Date:
      - Sat, 17 May 2025 17:20:46 GMT
      Server:
      - scaffolding on HTTPServer2
      X-Xss-Protection:
      - '0'
      X-Frame-Options:
      - SAMEORIGIN
      X-Content-Type-Options:
      - nosniff
      Server-Timing:
      - gfet4t7; dur=2033
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Transfer-Encoding:
      - chunked
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "candidates": [
            {
              "content": {
                "parts": [
                  {
                    "text": "Okay, this tells you that the function `get_weather` returned a hash (or dictionary) containing weather information. Let's break down what it means:\n\n*   **`get_weather`**:  This is the name of the function that was called. It's likely a function designed to retrieve weather data.\n\n*   **`{:temperature=\u003e72, :conditions=\u003e\"sunny\", :humidity=\u003e45}`**: This is the hash that the function returned. Hashes are data structures that store key-value pairs.  In this case:\n    *   **`:temperature =\u003e 72`**:  The key `:temperature` has the value `72`.  This probably means the temperature is 72 degrees (Fahrenheit or Celsius, depending on the context of the application).\n    *   **`:conditions =\u003e \"sunny\"`**: The key `:conditions` has the value `\"sunny\"`. This indicates the weather conditions are sunny.\n    *   **`:humidity =\u003e 45`**: The key `:humidity` has the value `45`. This likely represents the humidity as a percentage (45%).\n\n**In summary, the function `get_weather` provided weather information indicating that it's 72 degrees, sunny, and the humidity is 45%.**\n\nYou might see this kind of output in a programming environment like Ruby, where `=\u003e` is used to represent the association between keys and values in a hash.  Other languages might use different syntax (e.g., `{ \"temperature\": 72, ... }` in JSON or Python).\n"
                  }
                ],
                "role": "model"
              },
              "finishReason": "STOP",
              "avgLogprobs": -0.25730221349336979
            }
          ],
          "usageMetadata": {
            "promptTokenCount": 23,
            "candidatesTokenCount": 337,
            "totalTokenCount": 360,
            "promptTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 23
              }
            ],
            "candidatesTokensDetails": [
              {
                "modality": "TEXT",
                "tokenCount": 337
              }
            ]
          },
          "modelVersion": "gemini-2.0-flash"
        }
  recorded_at: Sat, 17 May 2025 17:20:46 GMT
recorded_with: VCR 6.3.1
